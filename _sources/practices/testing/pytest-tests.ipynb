{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f4df87b",
   "metadata": {},
   "source": [
    "Pytest Tests\n",
    "============\n",
    "\n",
    "Pytest is a testing framework for Python. In this document we'll discuss how to\n",
    "write tests for Pytest as well as some of the extra features that Pytest\n",
    "provides.\n",
    "\n",
    "For installation and other usage information, see the [Pytest tool guide](../../tools/pytest).\n",
    "\n",
    "```{contents}\n",
    ":backlinks: top\n",
    ":local:\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "Part 1: Writing tests\n",
    "---------------------\n",
    "\n",
    "In this section we'll discuss how to write tests for Pytest.\n",
    "\n",
    "### Part 1.1: Hello World\n",
    "\n",
    "Pytest expects tests to be located in files whose names begin with `test_` or\n",
    "end with `_test.py`.\n",
    "\n",
    "Individual tests are written in functions that begins with `test_` and contain\n",
    "one or more `assert` statements which determine if it passes or fails.\n",
    "\n",
    "Here's a simple example test that will always pass.\n",
    "\n",
    "```{code-block} python\n",
    ":linenos:\n",
    ":caption: test_hello_world.py\n",
    "\n",
    "def test_truth():\n",
    "    assert True\n",
    "```\n",
    "\n",
    "```{important}\n",
    "\n",
    "Do not duplicate test names. If you do, only the first test will be run and\n",
    "any duplicates will be ignored by Pytest.\n",
    "\n",
    "```\n",
    "\n",
    "To run the test use the command line to type `pytest` followed by the filename.\n",
    "\n",
    "```{code-block} console\n",
    ":caption: command line\n",
    "$ pytest test_hello_world.py\n",
    "```\n",
    "\n",
    "The result will look something like this.\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 1 item\n",
    "\n",
    "test_hello_world.py .                                    [100%]\n",
    "\n",
    "====================== 1 passed in 0.00s =======================\n",
    "```\n",
    "\n",
    "Congratulations, you've run your first Pytest test!\n",
    "\n",
    "### Part 1.2: Test failures\n",
    "\n",
    "Let's look at an example of a failing tests. In the following `test_lies()`\n",
    "function the assert statement fails, which will in turn cause that test to\n",
    "fail.\n",
    "\n",
    "```{code-block} python\n",
    ":linenos:\n",
    ":caption: test_hello_world.py\n",
    "\n",
    "def test_truth():\n",
    "    assert True\n",
    "\n",
    "def test_lies():\n",
    "    assert False\n",
    "```\n",
    "\n",
    "Here is what your test output looks like now.\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    "$ pytest test_hello_world.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 2 items\n",
    "\n",
    "test_hello_world.py .F                                   [100%]\n",
    "\n",
    "=========================== FAILURES ===========================\n",
    "__________________________ test_lies ___________________________\n",
    "\n",
    "    def test_lies():\n",
    ">       assert False\n",
    "E       assert False\n",
    "\n",
    "test_hello_world.py:5: AssertionError\n",
    "=================== short test summary info ====================\n",
    "FAILED test_hello_world.py::test_lies - assert False\n",
    "================= 1 failed, 1 passed in 0.05s ==================\n",
    "```\n",
    "\n",
    "### Part 1.3: Reading test output\n",
    "\n",
    "Let's take a closer look at that test output.\n",
    "\n",
    ":::{card}\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    ":emphasize-lines: 8\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 2 items\n",
    "\n",
    "test_hello_world.py .F                                   [100%]\n",
    "```\n",
    "\n",
    "This line indicates the progress of each test file and each test in the file is\n",
    "represented by a single character following the filename.\n",
    "\n",
    "| Test No | Symbol      | Means...           |\n",
    "|---------|-------------|--------------------|\n",
    "| 1       | `.` (green) | passing test       |\n",
    "| 2       | `F` (red)   | failing test       |\n",
    "|         | `[100%]`    | all tests were run |\n",
    "|         |             |                    |\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    ":emphasize-lines: \"11-\"\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 2 items\n",
    "\n",
    "test_hello_world.py .F                                   [100%]\n",
    "\n",
    "=========================== FAILURES ===========================\n",
    "__________________________ test_lies ___________________________\n",
    "\n",
    "    def test_lies():\n",
    ">       assert False\n",
    "E       assert False\n",
    "```\n",
    "\n",
    "This section of the output shows you detailed information about each failing\n",
    "test.\n",
    "\n",
    "| Output                  | Means...                                                 |\n",
    "|-------------------------|----------------------------------------------------------|\n",
    "| `_____ test_lies _____` | start of info about `test_lies()` failure                |\n",
    "| `>       assert False`  | the line where the failure happened, indicated by `>`    |\n",
    "| `E       assert False`  | more information about the error, indicated by a red `E` |\n",
    "|                         |                                                          |\n",
    "\n",
    "If this was an error in your code instead of a failing `assert` there might\n",
    "be multiple lines beginning with `E` and a lot more information. In this case\n",
    "though there's no additional information so it looks the same as the line above.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    ":emphasize-lines: \"18\"\n",
    "$ pytest test_hello_world.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 2 items\n",
    "\n",
    "test_hello_world.py .F                                   [100%]\n",
    "\n",
    "=========================== FAILURES ===========================\n",
    "__________________________ test_lies ___________________________\n",
    "\n",
    "    def test_lies():\n",
    ">       assert False\n",
    "E       assert False\n",
    "\n",
    "test_hello_world.py:5: AssertionError\n",
    "```\n",
    "\n",
    "This line is probably the most useful of all. It tells you the three most\n",
    "important pieces of information:\n",
    "\n",
    "| Output                | Means...                             |\n",
    "|-----------------------|--------------------------------------|\n",
    "| `test_hello_world.py` | the file where the error occurred     |\n",
    "| `5`                   | the line number that it happened on   |\n",
    "| `AssertionError`      | the exception class that was raised  |\n",
    "|                       |                                      |\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    "\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    ":emphasize-lines: \"19-\"\n",
    "$ pytest test_hello_world.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 2 items\n",
    "\n",
    "test_hello_world.py .F                                   [100%]\n",
    "\n",
    "=========================== FAILURES ===========================\n",
    "__________________________ test_lies ___________________________\n",
    "\n",
    "    def test_lies():\n",
    ">       assert False\n",
    "E       assert False\n",
    "\n",
    "test_hello_world.py:5: AssertionError\n",
    "=================== short test summary info ====================\n",
    "FAILED test_hello_world.py::test_lies - assert False\n",
    "================= 1 failed, 1 passed in 0.05s ==================\n",
    "```\n",
    "\n",
    "Finally, this line shows a summary of all the failures.\n",
    "\n",
    "| Output                | Means...                             |\n",
    "|-----------------------|--------------------------------------|\n",
    "| `test_hello_world.py` | the file where the error occurred    |\n",
    "| `test_lies`           | the test that failed                 |\n",
    "| `assert False`        | the code that failed                 |\n",
    "| `1 failed`            | total failing tests                  |\n",
    "| `1 passed`            | total passing tests                  |\n",
    "|                       |                                      |\n",
    "\n",
    ":::\n",
    "\n",
    "### Part 1.4: Testing functions\n",
    "\n",
    "Let's take a look at what a test for a piece of code might look like.\n",
    "\n",
    "Below we add to the {file}`test_hello_world.py` file a `increment()` function\n",
    "which returns `number` incremented by one.\n",
    "\n",
    "The `test_increment()` test calls the `increment()` function with an argument of\n",
    "`5` and assigns the result to the variable `answer`. Then it asserts that the\n",
    "`answer` should be `6`.\n",
    "\n",
    "```{code-block} python\n",
    ":linenos:\n",
    ":caption: test_hello_world.py\n",
    "\n",
    "def increment(number):\n",
    "    return number + 1\n",
    "\n",
    "def test_truth():\n",
    "    assert True\n",
    "\n",
    "def test_increment():\n",
    "    answer = increment(5)\n",
    "    assert answer == 6\n",
    "```\n",
    "\n",
    "### Part 1.5: Importing functions\n",
    "\n",
    "We typically do not keep our functions in the same file as our tests. This\n",
    "means in order to test our functions, we'll need to import them into the test\n",
    "file.\n",
    "\n",
    "Let's say we have a file called `my_project.py`.\n",
    "\n",
    "```{code-block} python\n",
    ":linenos:\n",
    ":caption: my_project.py\n",
    "def can_drink(age):\n",
    "    return age >= 21\n",
    "```\n",
    "\n",
    "We would typically name our test file `test_my_project.py`. Then we'd import\n",
    "the `can_drink` function from the `my_project` module before defining the test\n",
    "for it.\n",
    "\n",
    "```{code-block} python\n",
    ":linenos:\n",
    ":caption: test_my_project.py\n",
    "\n",
    "from my_project import can_drink\n",
    "\n",
    "def test_can_drink():\n",
    "    is_allowed = can_drink(5)\n",
    "    assert not is_allowed\n",
    "```\n",
    "\n",
    "\n",
    "### Part 1.6: More imports\n",
    "\n",
    "In larger projects it is common to break things into multiple files and\n",
    "directories. A common directory structure looks like this:\n",
    "\n",
    "```text\n",
    ".\n",
    "├── README.md\n",
    "├── my_project\n",
    "│   ├── __init__.py\n",
    "│   └── main.py\n",
    "├── setup.py\n",
    "└── tests\n",
    "    └── test_main.py\n",
    "```\n",
    "\n",
    "In a setup like this your code would be in the `my_project` directory and your\n",
    "tests in the `tests` directory.\n",
    "\n",
    "If we imagine that we renamed the `my_project.py` file to `my_project/main.py`,\n",
    "then we would need to modify the import statement in our test file.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "def test_can_drink():\n",
    "    is_allowed = can_drink(5)\n",
    "    assert not is_allowed\n",
    "```\n",
    "\n",
    "To run the tests you would then run the command\n",
    "\n",
    "```{code-block} console\n",
    ":caption: command line\n",
    "$ pytest tests/test_main.py\n",
    "```\n",
    "\n",
    "Or to run all tests in the `tests` directory simply:\n",
    "\n",
    "```{code-block} console\n",
    ":caption: command line\n",
    "$ pytest tests\n",
    "```\n",
    "\n",
    "\n",
    "```{important}\n",
    "\n",
    "You must run `pytest` from the root directory of your project for the imports\n",
    "to work properly.\n",
    "\n",
    "```\n",
    "\n",
    "Part 2: Skipping tests\n",
    "----------------------\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "[Pytest Docs > How to use skip and xfail to deal with tests that cannot succeed](https://docs.pytest.org/en/stable/how-to/skipping.html)\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "In this section we'll discuss how to skip tests.\n",
    "\n",
    "### Part 2.1: Skipping a test\n",
    "\n",
    "Sometimes we have a test that is not currently working for some reason--maybe\n",
    "it's a work in progress or represents something you want to implement at a\n",
    "later date. Here's an example in our old `test_hello_world.py` file.\n",
    "\n",
    "First you need to import the `pytest` module in your test. Then above the test\n",
    "function add the line {samp}`@pytest.mark.skip(reason=\"{EXPLANATION}\")` with a\n",
    "brief explanation of why it is being skipped.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_hello_world.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "def test_truth():\n",
    "    assert True\n",
    "\n",
    "@pytest.mark.skip(reason=\"an example of a test failure\")\n",
    "def test_lies():\n",
    "    assert False\n",
    "\n",
    "def test_increment():\n",
    "    answer = increment(5)\n",
    "    assert answer == 6\n",
    "```\n",
    "\n",
    "When you run the tests, your output will show a yellow `s` for skipped tests.\n",
    "\n",
    "```{code-block} pytest\n",
    "$ pytest test_hello_world.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 3 items\n",
    "\n",
    "test_hello_world.py .s.                                  [100%]\n",
    "\n",
    "================= 2 passed, 1 skipped in 0.00s =================\n",
    "```\n",
    "\n",
    "### Part 2.2: Skipping a failure\n",
    "\n",
    "Another way to do the same thing is to mark it as an expected failure. It is\n",
    "the same as above, except use `xfail` instead of `skip`.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_hello_world.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "def test_truth():\n",
    "    assert True\n",
    "\n",
    "@pytest.mark.xfail(reason=\"an example of a test failure\")\n",
    "def test_lies():\n",
    "    assert False\n",
    "\n",
    "def test_increment():\n",
    "    answer = increment(5)\n",
    "    assert answer == 6\n",
    "```\n",
    "\n",
    "In the output, the skipped test will be marked with a yellow `x`.\n",
    "\n",
    "```{code-block} pytest\n",
    "$ pytest test_hello_world.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 3 items\n",
    "\n",
    "test_hello_world.py .x.                                  [100%]\n",
    "\n",
    "================= 2 passed, 1 xfailed in 0.03s =================\n",
    "```\n",
    "\n",
    "### Part 2.3: Skipping sometimes\n",
    "\n",
    "Sometimes you may want to skip certain tests that only work in certain\n",
    "environments. For example, based on a developers operating system or the\n",
    "version of Python they are running.\n",
    "\n",
    "In these cases the `skipif` decorator is useful. The first argument is the\n",
    "condition under which to skip the test, then use the `reason` keyword argument\n",
    "as usual.\n",
    "\n",
    "```{code-block} python\n",
    "import sys\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.skipif(sys.platform != \"darwin\", reason=\"mac-specific testing\")\n",
    "def test_macos():\n",
    "  ...\n",
    "\n",
    "```\n",
    "\n",
    "Part 3: Exception Handling\n",
    "--------------------------\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "* [Pytest Docs > pytest.raises](https://docs.pytest.org/en/stable/reference/reference.html#pytest.raises)\n",
    "* [Pytest Docs > Assertions about expected exceptions](https://docs.pytest.org/en/stable/how-to/assert.html#assertions-about-expected-exceptions)\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "Sometimes our program may raise exceptions on purpose, in which case we need to\n",
    "be able to test those exceptions without causing the tests to fail.\n",
    "\n",
    "### Part 3.1: pytest.raises\n",
    "\n",
    "To test for a raised exception use `pytest.raises` as a context manager with\n",
    "the code that is being tested inside of the context manager.\n",
    "\n",
    "For example, the following code effectively asserts that when you call the\n",
    "`do_quit()` function a `SystemExit` exception is raised. (Which is how most\n",
    "Python programs exit, under the hood.)\n",
    "\n",
    "```{code-block} python\n",
    "import pytest\n",
    "\n",
    "from my_game import do_quit\n",
    "\n",
    "def test_do_quit():\n",
    "    with pytest.raises(SystemExit):\n",
    "      # code to test\n",
    "      do_quit()\n",
    "```\n",
    "\n",
    "### Part 3.1: Exception messages\n",
    "\n",
    "Sometimes just checking the exception class isn't enough -- we have to test for\n",
    "a specific exception message. For example, our program may raise a `ValueError`\n",
    "in a function. However `ValueError` exceptions are very common.\n",
    "\n",
    "In that case you can use the optional `as` part of the `pytest.raises` context\n",
    "manager to get the exception info, then run the code you wish to test as\n",
    "before. Then *after* the with statement, you can add an assert statement on\n",
    "`info.value`.\n",
    "\n",
    "```{code-block} python\n",
    "import pytest\n",
    "\n",
    "from my_game import inventory_remove\n",
    "\n",
    "def test_inventory_remove_with_invalid_argument():\n",
    "    with pytest.raises(ValueError) as info:\n",
    "        # code to test\n",
    "        inventory_remove(5)\n",
    "\n",
    "    # check the exception message\n",
    "    message = str(info.value)\n",
    "    assert \"inventory_remove() expected an item key (str).\" in message\n",
    "```\n",
    "\n",
    "### Part 3.3: Message patterns\n",
    "\n",
    "Another way to test the error message is to use the `match` keyword argument in\n",
    "`pytest.raises()`.\n",
    "\n",
    "```{code-block} python\n",
    "import pytest\n",
    "\n",
    "from my_game import Player\n",
    "\n",
    "def test_buy():\n",
    "    player = Player(gems=10)\n",
    "    sword = Sword(price=90)\n",
    "\n",
    "    with pytest.raises(ValueError, match=\"you are 80 gems short\") as info:\n",
    "        # code to test\n",
    "        player.buy(sword)\n",
    "```\n",
    "\n",
    "The `match` argument can be a regular expression, so you could also do.\n",
    "\n",
    "```{code-block} python\n",
    "import pytest\n",
    "\n",
    "from my_game import Player\n",
    "\n",
    "def test_buy():\n",
    "    player = Player(gems=10)\n",
    "    sword = Sword(price=90)\n",
    "\n",
    "    with pytest.raises(ValueError, match=r\"you are \\d+ gems short\") as info:\n",
    "        # code to test\n",
    "        player.buy(sword)\n",
    "```\n",
    "\n",
    "Part 4: Testing printed output\n",
    "------------------------------\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "[Pytest Docs > How to capture stdout/stderr output](https://docs.pytest.org/en/stable/how-to/capture-stdout-stderr.html)\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "Sometimes we need to test not what is returned, but what is printed to the\n",
    "screen. To do this we can use the special fixture (more on those later)\n",
    "`capsys`.\n",
    "\n",
    "### Part 4.1: Testing stdout\n",
    "\n",
    "When you call the `print()` function the string that you pass is sent to a\n",
    "special file called {term}`stdout` that your terminal knows to display to the\n",
    "end user.\n",
    "\n",
    "When we are testing something that prints to the screen, add `capsys` to the\n",
    "function definition to let Pytest know that it should capture the system output\n",
    "and save it for us.\n",
    "\n",
    "\n",
    "```{code-block} python\n",
    "def test_write(capsys):\n",
    "  write(\"hello\", lines_after=3)\n",
    "  output = capsys.readouterr().out\n",
    "\n",
    "  assert output.endswith(\"\\n\\n\\n\")\n",
    "```\n",
    "\n",
    "Note that every time you call `readouterr()` it sets the `out` attribute to all\n",
    "of the content that has been sent to `stdout` since the function started or the\n",
    "last time `readouterr()` was called.\n",
    "\n",
    "```{code-block} python\n",
    ":linenos:\n",
    ":emphasize-lines: \"6, 12\"\n",
    "def test_stdout(capsys):\n",
    "    print(\"a\")\n",
    "    print(\"b\")\n",
    "    print(\"c\")\n",
    "\n",
    "    output_1 = capsys.readouterr().out\n",
    "\n",
    "    print(\"x\")\n",
    "    print(\"y\")\n",
    "    print(\"z\")\n",
    "\n",
    "    output_2 = capsys.readouterr().out\n",
    "\n",
    "    assert output_1 == \"a\\nb\\nc\\n\"\n",
    "    assert output_2 == \"x\\ny\\nz\\n\"\n",
    "\n",
    "```\n",
    "\n",
    "In this example\n",
    "\n",
    "* `output_1` on line `6` will contain what was printed on lines `2`-`4`\n",
    "* `output_2` on line `12` will contain what was printed on lines `8`-`10`\n",
    "\n",
    "### Part 4.2: Testing stderr\n",
    "\n",
    "Many command line programs print errors to a separate special file called\n",
    "`stderr`. This allows end users and other programs to do things that involve\n",
    "handling error messages differently from normal program output. For example to\n",
    "silence all errors or save a file that contains just the errors.\n",
    "\n",
    "In Python, to print to `stderr` you simply include the `sys` module, then add\n",
    "the keyword argument `file=sys.stderr` to your print statement.\n",
    "\n",
    "Here's an example `error()` function which adds a red `Error` string to the\n",
    "beginning of the message then prints all arguments to `stderr`.\n",
    "\n",
    "```{code-block} python\n",
    "import sys\n",
    "\n",
    "def error(*args):\n",
    "    print(\"\\x1b[31mError\\x1b[0m\", *args, file=sys.stderr)\n",
    "```\n",
    "\n",
    "To write a test for this we would use `capsys` just like before, but look for\n",
    "`err` instead of `out`.\n",
    "\n",
    "```{code-block} python\n",
    "def test_error(capsys):\n",
    "    error(\"Please reconsider your life choices and try again.\")\n",
    "\n",
    "    output = capsys.readouterr().err\n",
    "\n",
    "    assert \"reconsider\" in output\n",
    "```\n",
    "\n",
    "### Part 4.3: Testing both\n",
    "\n",
    "If you need to check what was printed to both `stdout` and `stderr`, you need\n",
    "to make sure that `readouterr()` is only called once. You can accomplish this\n",
    "by assigning it to a variable.\n",
    "\n",
    "Let's say we're testing a function that starts like this:\n",
    "\n",
    "```{code-block} python\n",
    "import sys\n",
    "\n",
    "def do_thing(*args):\n",
    "    print(\"debug: Trying to do the thing:\", *args)\n",
    "\n",
    "    if not args:\n",
    "        print(\"Which thing should I do?\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    ...\n",
    "```\n",
    "\n",
    "In our test, we'll save the result of `readouterr()` to the variable\n",
    "`captured`, then check `captured.out` and `captured.err` in our assert\n",
    "statements.\n",
    "\n",
    "```{code-block} python\n",
    "def test_do_thing(capsys):\n",
    "    do_thing()\n",
    "\n",
    "    captured = capsys.readouterr()\n",
    "\n",
    "    assert \"Trying to do the thing\" in captured.out\n",
    "    assert \"Which thing\" in captured.err\n",
    "```\n",
    "\n",
    "Part 5: Parametrization\n",
    "-----------------------\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "[Pytest Docs > How to parametrize fixtures and test functions](https://docs.pytest.org/en/stable/how-to/parametrize.html#parametrize-basics)\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "Parametrization is used to combine the multiple test that are *almost* exactly\n",
    "the same into one test with several {term}`test cases <test case>` that are\n",
    "stored and run as a list of arguments to a single test function.\n",
    "\n",
    "### Part 5.1: Parametrize\n",
    "\n",
    "Remember our `can_drink()` function? Let's say we were very responsible and\n",
    "wrote a whole bunch of tests for it.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "def test_can_drink_15():\n",
    "    is_allowed = can_drink(15)\n",
    "    assert not is_allowed\n",
    "\n",
    "def test_can_drink_0():\n",
    "    is_allowed = can_drink(0)\n",
    "    assert not is_allowed\n",
    "\n",
    "def test_can_drink_negative():\n",
    "    is_allowed = can_drink(-5)\n",
    "    assert not is_allowed\n",
    "\n",
    "def test_can_drink_float():\n",
    "    is_allowed = can_drink(17.5)\n",
    "    assert not is_allowed\n",
    "\n",
    "def test_can_drink_21():\n",
    "    is_allowed = can_drink(21)\n",
    "    assert is_allowed\n",
    "\n",
    "def test_can_drink_100():\n",
    "    is_allowed = can_drink(100)\n",
    "    assert is_allowed\n",
    "```\n",
    "\n",
    "Parametrization allows us to collapse that down into just one test with a few\n",
    "modifications.\n",
    "\n",
    "#### A. Identify differences\n",
    "\n",
    "Identify what is different between the test functions.\n",
    "\n",
    "```{code-block-hl} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "def test_can_drink_15():\n",
    "    is_allowed = can_drink(!!!15!!!)\n",
    "    assert !!!not is_allowed!!!\n",
    "\n",
    "def test_can_drink_0():\n",
    "    is_allowed = can_drink(!!!0!!!)\n",
    "    assert !!!not is_allowed!!!\n",
    "\n",
    "def test_can_drink_negative():\n",
    "    is_allowed = can_drink(!!!-5!!!)\n",
    "    assert !!!not is_allowed!!!\n",
    "\n",
    "def test_can_drink_float():\n",
    "    is_allowed = can_drink(!!!17.5!!!)\n",
    "    assert !!!not is_allowed!!!\n",
    "\n",
    "def test_can_drink_21():\n",
    "    is_allowed = can_drink(!!!21!!!)\n",
    "    assert !!!is_allowed!!!\n",
    "\n",
    "def test_can_drink_100():\n",
    "    is_allowed = can_drink(!!!100!!!)\n",
    "    assert !!!is_allowed!!!\n",
    "```\n",
    "\n",
    "You can see that there are two things that change in these tests:\n",
    "\n",
    "1. The age that is passed to `can_drink()`\n",
    "2. Whether we expect `can_drink()` to return `True` or `False`.\n",
    "\n",
    "#### B. Add `age` variable\n",
    "\n",
    "We'll parametrize the age passed to the `can_drink()` function.\n",
    "\n",
    "1. Replace the argument passed to `can_drink()` with a variable `age`.\n",
    "2. Add `age` as a parameter in the declaration of `test_can_drink()`.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"3-4\"\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "def test_can_drink(age):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert not is_allowed\n",
    "```\n",
    "\n",
    "#### C. Add `expected` variable\n",
    "\n",
    "Next we'll parametrize the expected return value.\n",
    "\n",
    "1. Add `expected` as a parameter in the declaration of `test_can_drink()`.\n",
    "2. Change the assert statement condition to `== expected` (instead of\n",
    "   `is_allowed` or `not is_allowed`) .\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"3,5\"\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "def test_can_drink(age, expected):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert is_allowed == expected\n",
    "```\n",
    "\n",
    "#### D. Add decorator\n",
    "\n",
    "Setup the test for parametrization.\n",
    "\n",
    "1. Import `pytest`.\n",
    "2. Call `@pytest.mark.parametrize()` immediately above the test function.\n",
    "   * The first argument should be list containing the parameter names from the\n",
    "     test function, in this case `age` and `expected`\n",
    "   * The second will eventually list of tuples, but let's start with an empty list\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"5-6\"\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize([\"age\", \"expected\"], [\n",
    "])\n",
    "def test_can_drink(age, expected):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert is_allowed == expected\n",
    "```\n",
    "\n",
    "#### E. Add values for one test\n",
    "\n",
    "Each tuple represents what would have been a test otherwise, called a\n",
    "{term}`test case`.\n",
    "\n",
    "Each should contain the values for the variables in the same order they show up\n",
    "in in the first argument and the function declaration, in this case the values\n",
    "for `age` and `expected`.\n",
    "\n",
    "If we look at the first test, above, those values are `15` for `age` and\n",
    "`False` for `expected`.\n",
    "\n",
    "1. Add a tuple to the empty list from above that contains the values `15` and `False`.\n",
    "2. Now you can run your tests and it should pass.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"6\"\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize([\"age\", \"expected\"], [\n",
    "    (15, False),\n",
    "])\n",
    "def test_can_drink(age, expected):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert is_allowed == expected\n",
    "```\n",
    "\n",
    "As it is written now, this is functionally the same as `test_can_drink_15()`\n",
    "from above. You should be able to run this test now.\n",
    "\n",
    "#### F. Add assert message\n",
    "\n",
    "When using parametrization, it is helpful to have a different assert message\n",
    "for each test case. That way if it does fail you can tell which one is the\n",
    "problem.\n",
    "\n",
    "1. Add `message` as a parameter in the declaration of `test_can_drink()`.\n",
    "1. Add `\"message\"` to the end of the list of variable names in the\n",
    "   `@pytest.mark.paramaratize()` call\n",
    "2. In the test add an assert message that that contains the variable `message`\n",
    "3. Add a string to the end of the test case tuple describing this specific case\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"5, 6, 8, 10-\"\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize([\"age\", \"expected\", \"message\"], [\n",
    "    (15, False, \"False when age is less than 21\"),\n",
    "])\n",
    "def test_can_drink(age, expected, message):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert is_allowed == expected, \\\n",
    "        f\"can_drink() should return {message}\"\n",
    "```\n",
    "\n",
    "#### G. Add remaining test cases\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"7-11\"\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize([\"age\", \"expected\", \"message\"], [\n",
    "    (15, False, \"False when age is less than 21\"),\n",
    "    (0, False, \"False when age is zero\"),\n",
    "    (-5, False, \"False when age is a negative int\"),\n",
    "    (17.5, False, \"False when age is a negative float\"),\n",
    "    (21, True, \"True when age is exactly 21\"),\n",
    "    (100, True, \"True when age is over 21\"),\n",
    "])\n",
    "def test_can_drink(age, expected, message):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert is_allowed == expected, \\\n",
    "        f\"can_drink() should return {message}\"\n",
    "```\n",
    "\n",
    "#### H. Run the tests\n",
    "\n",
    "If you run your tests in verbose mode with the `-v` flag, you will see a line\n",
    "for each test case with the values from each tuple inside brackets and\n",
    "separated by dashes. (I truncated the commit message here for formatting\n",
    "purposes, but your test output will show the whole thing.)\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    "$ pytest -v test_my_project.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 6 items\n",
    "\n",
    "test_my_project.py::test_can_drink[15-False-False...] PASSED    [ 16%]\n",
    "test_my_project.py::test_can_drink[0-False-False...] PASSED     [ 33%]\n",
    "test_my_project.py::test_can_drink[-5-False-False...] PASSED    [ 50%]\n",
    "test_my_project.py::test_can_drink[17.5-False-False...] PASSED  [ 66%]\n",
    "test_my_project.py::test_can_drink[21-True-True...] PASSED      [ 83%]\n",
    "test_my_project.py::test_can_drink[100-True-True...] PASSED     [100%]\n",
    "\n",
    "====================== 6 passed in 0.01s =======================\n",
    "```\n",
    "\n",
    "#### I. Failing test output\n",
    "\n",
    "Here's an example of what it looks like when a parametrized test fails.\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    ":emphasize-lines: \"14, 16-17, 42\"\n",
    "$ pytest -v test_my_project.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 6 items\n",
    "\n",
    "test_my_project.py::test_can_drink[15-False-False...] PASSED    [ 16%]\n",
    "test_my_project.py::test_can_drink[0-False-False...] PASSED     [ 33%]\n",
    "test_my_project.py::test_can_drink[-5-False-False...] PASSED    [ 50%]\n",
    "\n",
    "=========================== FAILURES ===========================\n",
    "___ test_can_drink[-5-True-False when age is a negative int] ___\n",
    "\n",
    "age = -5, expected = True\n",
    "message = 'False when age is a negative int'\n",
    "\n",
    "    @pytest.mark.parametrize([\"age\", \"expected\", \"message\"], [\n",
    "        (15, False, \"False when age is less than 21\"),\n",
    "        (0, False, \"False when age is zero\"),\n",
    "        (-5, True, \"False when age is a negative int\"),\n",
    "        (17.5, False, \"False when age is a negative float\"),\n",
    "        (21, True, \"True when age is exactly 21\"),\n",
    "        (100, True, \"True when age is over 21\"),\n",
    "    ])\n",
    "    def test_can_drink(age, expected, message):\n",
    "        is_allowed = can_drink(age)\n",
    ">       assert is_allowed == expected, \\\n",
    "            f\"can_drink() should return {message}\"\n",
    "E       AssertionError: can_drink() should return False when age is a negative int\n",
    "E       assert == failed. [pytest-clarity diff shown]\n",
    "E\n",
    "E         LHS vs RHS shown below\n",
    "E\n",
    "E         False\n",
    "E         True\n",
    "E\n",
    "\n",
    "test_my_project.py:24: AssertionError\n",
    "=================== short test summary info ====================\n",
    "FAILED test_my_project.py::test_can_drink[-5-True-False when age is a negative int] - AssertionError: can_drink() should return False when age is...\n",
    "!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!\n",
    "================= 1 failed, 2 passed in 0.08s ==================\n",
    "```\n",
    "\n",
    "You can figure out which test is failing by looking at:\n",
    "\n",
    "* The line starting with `___ test_can_drink` contains the parameters values in brackets separated by dashes\n",
    "* The lines immediately after that contain the more easily readable parameter names and values.\n",
    "* The line starting with `FAILED` in the test summary contains the parameters values in brackets separated by dashes\n",
    "\n",
    "### Part 5.2: Skipping instances\n",
    "\n",
    "You may want to include test cases that you know will fail to, for example,\n",
    "document something that is broken or not supported.\n",
    "\n",
    "To do this, make a test instance that calls `pytest.param()` (instead of a\n",
    "tuple) and include the keyword argument `marks=pytest.mark.xfail` to indicate\n",
    "that it will fail.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_my_project.py\n",
    ":linenos:\n",
    ":emphasize-lines: 13\n",
    "\n",
    "from my_project.main import can_drink\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    [\"age\", \"expected\"], [\n",
    "        (15, False),\n",
    "        (0, False),\n",
    "        (-5, False),\n",
    "        (17.5, False),\n",
    "        (21, True),\n",
    "        (100, True),\n",
    "        pytest.param(\"100\", None, marks=pytest.mark.xfail),\n",
    "\n",
    "])\n",
    "def test_can_drink(age, expected):\n",
    "    is_allowed = can_drink(age)\n",
    "    assert is_allowed == expected\n",
    "```\n",
    "\n",
    "In this example we add a failing test case for passing a string to\n",
    "`can_drink()` since it's not supported. (`expected` is `None`, but it doesn't\n",
    "matter because the exception will happen on line `17`.)\n",
    "\n",
    "When we run the tests in verbose mode Pytest will indicate that that test was\n",
    "marked as `XFAIL`.\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    ":emphasize-lines: 15\n",
    "\n",
    "$ pytest -v test_my_project.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 7 items\n",
    "\n",
    "test_my_project.py::test_can_drink[15-False] PASSED      [ 14%]\n",
    "test_my_project.py::test_can_drink[0-False] PASSED       [ 28%]\n",
    "test_my_project.py::test_can_drink[-5-False] PASSED      [ 42%]\n",
    "test_my_project.py::test_can_drink[17.5-False] PASSED    [ 57%]\n",
    "test_my_project.py::test_can_drink[21-True] PASSED       [ 71%]\n",
    "test_my_project.py::test_can_drink[100-True] PASSED      [ 85%]\n",
    "test_my_project.py::test_can_drink[100-None] XFAIL       [100%]\n",
    "\n",
    "================= 6 passed, 1 xfailed in 0.02s =================\n",
    "```\n",
    "\n",
    "Part 6: Setup and Teardown\n",
    "--------------------------\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "[Pytest Docs > classic xunit-style setup](https://docs.pytest.org/en/6.2.x/xunit_setup.html)\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "For tests that depend on information from the environment, it is important that each\n",
    "test start with a clean slate. This is generally accomplished with setup and\n",
    "teardown code--that is, code designated to run at the start and end of a\n",
    "particular process.\n",
    "\n",
    "In this section we'll talk about a couple of the different ways that you can do\n",
    "this in Pytest tests.\n",
    "\n",
    "### Part 6.1: Per-module setup/teardown functions\n",
    "\n",
    "Some setup or teardown steps only need to be done once per module (or file).\n",
    "For example, you may need to open and close a connection to a database, create\n",
    "and delete temporary directories, load the contents of a file, or initialize\n",
    "global variables.\n",
    "\n",
    "In Pytest tests you can do this by simply defining a `setup_module()` function\n",
    "which will be executed once per file before all tests and/or a\n",
    "`teardown_module()` which will be run once per file after all tests.\n",
    "\n",
    "Here is an example that loads json files (downloaded from\n",
    "`https://jsonplaceholder.typicode.com/`) and stores the data in a global\n",
    "variable `STATE` which test all test functions can access.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_setup_teardown.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"4-12, 16, 23\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def setup_module(module):\n",
    "    \"\"\"Initialize STATE global variable and load from json testdata.\"\"\"\n",
    "    global STATE\n",
    "    STATE = {}\n",
    "\n",
    "    for resource in [\"users\", \"todos\"]:\n",
    "        file = Path(__file__).parent / \".data\" / f\"{resource}.json\"\n",
    "        with file.open() as fh:\n",
    "            STATE[resource] = json.load(fh)\n",
    "\n",
    "def test_user():\n",
    "    \"\"\"Test that the first user was loaded from the users.json file.\"\"\"\n",
    "    user = STATE[\"users\"][0]\n",
    "\n",
    "    assert user[\"id\"] == 1\n",
    "    assert user[\"name\"] == \"Leanne Graham\"\n",
    "\n",
    "def test_todo():\n",
    "    \"\"\"Test that the first todo was loaded from the todos.json file.\"\"\"\n",
    "    todo = STATE[\"todos\"][0]\n",
    "\n",
    "    assert todo[\"id\"] == 1\n",
    "    assert todo[\"title\"] == \"delectus aut autem\"\n",
    "    assert not todo[\"completed\"]\n",
    "```\n",
    "\n",
    "### Part 6.2: Per-test setup/teardown functions\n",
    "\n",
    "It is important to start each test with a clean slate to avoid test corruption.\n",
    "\n",
    "#### A. Test corruption\n",
    "\n",
    "Test corruption is when changes made to to one test unexpectedly breaks other\n",
    "tests.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_setup_teardown.py\n",
    ":linenos:\n",
    ":lineno-start: 28\n",
    ":emphasize-lines: \"4, 12\"\n",
    "\n",
    "def test_modify_state():\n",
    "    \"\"\"Change the STATE data\"\"\"\n",
    "    todo = STATE[\"todos\"][0]\n",
    "    todo[\"completed\"] = True\n",
    "\n",
    "    assert todo[\"completed\"]\n",
    "\n",
    "def test_check_modified_state():\n",
    "    \"\"\"Check the same data that was modified above.\"\"\"\n",
    "    todo = STATE[\"todos\"][0]\n",
    "\n",
    "    assert not todo[\"completed\"]\n",
    "```\n",
    "\n",
    "When run `test_check_modified_state()` will fail because `todo[\"completed\"]`\n",
    "was changed in the previous test.\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    "$ pytest -v test_setup_teardown.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 4 items\n",
    "\n",
    "tests/test_setup_teardown.py ...F                        [100%]\n",
    "\n",
    "=========================== FAILURES ===========================\n",
    "__________________ test_check_modified_state ___________________\n",
    "\n",
    "    def test_check_modified_state():\n",
    "        \"\"\"Check the same data that was modified above.\"\"\"\n",
    "        todo = STATE[\"todos\"][0]\n",
    "\n",
    ">       assert not todo[\"completed\"]\n",
    "E       assert not True\n",
    "\n",
    "tests/test_setup_teardown.py:41: AssertionError\n",
    "=================== short test summary info ====================\n",
    "FAILED tests/test_setup_teardown.py::test_check_modified_state - assert not True\n",
    "================= 1 failed, 3 passed in 0.05s ==================\n",
    "```\n",
    "\n",
    "#### B. Define `setup_function()`\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{tip}\n",
    "\n",
    "Sequence objects have a `.copy()` method that makes a shallow copy. That means\n",
    "that any nested objects are copied as references, so if you change the contents\n",
    "of the child object in the copy it will also change the contents of the child\n",
    "object in the original.\n",
    "\n",
    "Use `deepcopy()` to make copies of all nested child objects and contents\n",
    "recursively.\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "To avoid this we will define a `setup_function()` function which will be run\n",
    "before each test.\n",
    "\n",
    "This setup function will copy the data saved in the `STATE` variable to a new\n",
    "global variable `DATA`. The tests will then look at and make any changes to\n",
    "`DATA` and leave `STATE` alone.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_setup_teardown.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"2, 15-18, 22, 29, 37, 44\"\n",
    "\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "def setup_module(module):\n",
    "    \"\"\"Initialize STATE global variable and load from json testdata.\"\"\"\n",
    "    global STATE\n",
    "    STATE = {}\n",
    "\n",
    "    for resource in [\"users\", \"todos\"]:\n",
    "        file = Path(__file__).parent / \".data\" / f\"{resource}.json\"\n",
    "        with file.open() as fh:\n",
    "            STATE[resource] = json.load(fh)\n",
    "\n",
    "def setup_function(function):\n",
    "    \"\"\"Revert data to its original state before each test.\"\"\"\n",
    "    global DATA\n",
    "    DATA = deepcopy(STATE)\n",
    "\n",
    "def test_user():\n",
    "    \"\"\"Test that the first user was loaded from the users.json file.\"\"\"\n",
    "    user = DATA[\"users\"][0]\n",
    "\n",
    "    assert user[\"id\"] == 1\n",
    "    assert user[\"name\"] == \"Leanne Graham\"\n",
    "\n",
    "def test_todo():\n",
    "    \"\"\"Test that the first todo was loaded from the todos.json file.\"\"\"\n",
    "    todo = DATA[\"todos\"][0]\n",
    "\n",
    "    assert todo[\"id\"] == 1\n",
    "    assert todo[\"title\"] == \"delectus aut autem\"\n",
    "    assert not todo[\"completed\"]\n",
    "\n",
    "def test_modify_state():\n",
    "    \"\"\"Change the DATA data\"\"\"\n",
    "    todo = DATA[\"todos\"][0]\n",
    "    todo[\"completed\"] = True\n",
    "\n",
    "    assert todo[\"completed\"]\n",
    "\n",
    "def test_check_modified_state():\n",
    "    \"\"\"Check the same data that was modified above.\"\"\"\n",
    "    todo = DATA[\"todos\"][0]\n",
    "\n",
    "    assert not todo[\"completed\"]\n",
    "```\n",
    "\n",
    "Now that each test starts with the same known set of data, all the tests pass.\n",
    "\n",
    "```{code-block} pytest\n",
    ":caption: command line output\n",
    "$ pytest -v test_setup_teardown.py\n",
    "===================== test session starts ======================\n",
    "platform darwin -- Python 3.9.1, pytest-7.0.1, pluggy-1.0.0\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ~/python-class, configfile: pyproject.toml\n",
    "plugins: pylama-8.3.7, typeguard-2.13.3\n",
    "collected 4 items\n",
    "\n",
    "tests/test_setup_teardown.py ....                        [100%]\n",
    "\n",
    "====================== 4 passed in 0.01s =======================\n",
    "```\n",
    "\n",
    "Part 7: Fixtures\n",
    "----------------\n",
    "\n",
    "`````{margin}\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "[Pytest Docs > How to use fixtures](https://docs.pytest.org/en/stable/how-to/fixtures.html)\n",
    "\n",
    "```\n",
    "\n",
    "`````\n",
    "\n",
    "In tests we often need to do similar setup in many tests. As a project becomes\n",
    "larger, it becomes unwieldy to come up with sample data over and over again.\n",
    "\n",
    "{term}`Fixtures <fixture>` are one way to approach this problem. In general\n",
    "terms, fixtures are the shared context of the {term}`test suite`. In fact, you\n",
    "the setup and teardown functions from [Part 6](#part-6-setup-and-teardown) are\n",
    "one example of fixtures in the most general sense.\n",
    "\n",
    "Different languages and testing frameworks have different systems for\n",
    "supporting fixtures, usually involving some form of setup/teardown.\n",
    "Traditionally though, the term fixture refers to a single record of test\n",
    "data--for example a single user dictionary from `DATA`.\n",
    "\n",
    "Pytest has a unique and powerful approach to fixtures which can entirely\n",
    "replace setup and teardown functions. It might take a minute to wrap your head\n",
    "around it though.\n",
    "\n",
    "### Part 7.1: Basic Fixture\n",
    "\n",
    "In Pytest fixtures are set up as functions decorated with the `@pytest.fixture`\n",
    "decorator and the return value is the fixture data itself.\n",
    "\n",
    "Tests request a fixtures by declaring them as parameters, which can then be\n",
    "used in the function like a variable.\n",
    "\n",
    "Here's an example of the {term}`\"Hello World\" <hello world>` of Pytest fixtures.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def true():\n",
    "    return True\n",
    "\n",
    "def test_truth(true):\n",
    "    assert true == True\n",
    "```\n",
    "\n",
    "Let's take a closer look.\n",
    "\n",
    "{{ leftcol }}\n",
    "\n",
    "1\\. First we import `pytest`.\n",
    "\n",
    "{{ rightcol }}\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    "import pytest\n",
    "\n",
    "```\n",
    "\n",
    "{{ newrow }}\n",
    "\n",
    "2\\. The decorator `@pytest.fixture` tells Pytest to treat the next function as a fixture.\n",
    "\n",
    "{{ rightcol }}\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":lineno-start: 3\n",
    ":emphasize-lines: 1\n",
    "\n",
    "@pytest.fixture\n",
    "def true():\n",
    "    return True\n",
    "```\n",
    "\n",
    "{{ newrow }}\n",
    "\n",
    "3\\. The return value from the fixture function is the fixture value.\n",
    "\n",
    "In this case the name of the fixture is `true` and the value is `True`.\n",
    "\n",
    "{{ rightcol }}\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":lineno-start: 3\n",
    ":emphasize-lines: 2-3\n",
    "\n",
    "@pytest.fixture\n",
    "def true():\n",
    "    return True\n",
    "```\n",
    "\n",
    "{{ newrow }}\n",
    "\n",
    "4\\. The test requests a fixture by declaring the fixture name as a parameter in the\n",
    "test function.\n",
    "\n",
    "In this case the fixture named `true` is added as a parameter `test_truth()`\n",
    "test.\n",
    "\n",
    "{{ rightcol }}\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":lineno-start: 7\n",
    ":emphasize-lines: 1\n",
    "def test_truth(true):\n",
    "    assert true == True\n",
    "```\n",
    "\n",
    "{{ newrow }}\n",
    "\n",
    "5\\. Finally, we use the fixture name in the test the same way we would any\n",
    "other variable.\n",
    "\n",
    "{{ rightcol }}\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":lineno-start: 7\n",
    ":emphasize-lines: 2\n",
    "def test_truth(true):\n",
    "    assert true == True\n",
    "```\n",
    "\n",
    "{{ endcols }}\n",
    "\n",
    "#### Example\n",
    "\n",
    "Fixtures can be used to store reusable data of all kinds, from strings to\n",
    "dictionaries to `pathlib.Path` objects.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"9-17, 19-22, 27-28, 31-32\"\n",
    "from pathlib import Path\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def true():\n",
    "    return True\n",
    "\n",
    "@pytest.fixture\n",
    "def bret():\n",
    "    \"\"\"A user dictionary\"\"\"\n",
    "    return {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"Leanne Graham\",\n",
    "    \"username\": \"Bret\",\n",
    "    \"email\": \"Sincere@april.biz\",\n",
    "  }\n",
    "\n",
    "@pytest.fixture\n",
    "def fixturedir():\n",
    "    \"\"\"Path object to fixture data files\"\"\"\n",
    "    return Path(__file__).parent / \".data\"\n",
    "\n",
    "def test_truth(true):\n",
    "    assert true == True\n",
    "\n",
    "def test_something_with_a_user(bret):\n",
    "    user = User(bret)\n",
    "    assert user.id == 1\n",
    "\n",
    "def test_something_from_fixturedir(fixturedir):\n",
    "    user = User(filename=fixturedir/\"users.json\")\n",
    "    assert user.id == 1\n",
    "```\n",
    "\n",
    "### Part 7.2: Fixtures Requesting Fixtures\n",
    "\n",
    "The same way that a test can request a fixture, a fixture can request another\n",
    "fixture--by declaring it as a parameter to the fixture function.\n",
    "\n",
    "```{literalinclude} ../../../pythonclass/lessons/test_fixture_fixtures.py\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"14, 19\"\n",
    ":start-at: from pathlib\n",
    "```\n",
    "\n",
    "### Part 7.3: Scope\n",
    "\n",
    "In Pytest you can choose what {term}`scope <fixture scope>` a fixture is in--that is, at what\n",
    "level tests should share the fixture before it is destroyed. To do this pass\n",
    "{samp}`scope={SCOPE}` to the `@pytest.fixture()` decorator.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":emphasize-lines: 1\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def my_fixture():\n",
    "  ...\n",
    "```\n",
    "\n",
    "| Scope        | Shared with                            | When Fixture is Destroyed |\n",
    "|--------------|----------------------------------------|---------------------------|\n",
    "| **function** | a single test function *default*       | end of each test          |\n",
    "| **class**    | all test methods in a class            | last test in the class    |\n",
    "| **module**   | all tests in a module (file)           | last test in the module   |\n",
    "| **package**  | all tests in the package (directory)   | last test in the package  |\n",
    "| **session**  | all tests to be run                    | last test to be run       |\n",
    "\n",
    "The `STATE` and `DATA` setup and teardown could be written using fixtures instead.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: test_fixtures.py\n",
    ":linenos:\n",
    ":emphasize-lines: \"8-19, 22-25, 28-31, 34, 36, 42, 44, 51, 53, 59, 61\"\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def state():\n",
    "    \"\"\"Load state from json testdata.\"\"\"\n",
    "    data = {}\n",
    "\n",
    "    for resource in [\"users\", \"todos\"]:\n",
    "        #  file = Path(__file__).parent / \".data\" / f\"{resource}.json\"\n",
    "        file = Path.cwd() / f\"{resource}.json\"\n",
    "        with file.open() as fh:\n",
    "            data[resource] = json.load(fh)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def users(state):\n",
    "    \"\"\"Return a fresh set of data for each function.\"\"\"\n",
    "    return deepcopy(state[\"users\"])\n",
    "\n",
    "\n",
    "@pytest.fixture()\n",
    "def todos(state):\n",
    "    \"\"\"Return a fresh set of data for each function.\"\"\"\n",
    "    return deepcopy(state[\"todos\"])\n",
    "\n",
    "\n",
    "def test_user(users):\n",
    "    \"\"\"Test that the first user was loaded from the users.json file.\"\"\"\n",
    "    user = users[0]\n",
    "\n",
    "    assert user[\"id\"] == 1\n",
    "    assert user[\"name\"] == \"Leanne Graham\"\n",
    "\n",
    "\n",
    "def test_todo(todos):\n",
    "    \"\"\"Test that the first todo was loaded from the todos.json file.\"\"\"\n",
    "    todo = todos[0]\n",
    "\n",
    "    assert todo[\"id\"] == 1\n",
    "    assert todo[\"title\"] == \"delectus aut autem\"\n",
    "    assert not todo[\"completed\"]\n",
    "\n",
    "\n",
    "def test_modify_state(todos):\n",
    "    \"\"\"Change the data\"\"\"\n",
    "    todo = todos[0]\n",
    "    todo[\"completed\"] = True\n",
    "\n",
    "    assert todo[\"completed\"]\n",
    "\n",
    "\n",
    "def test_check_modified_state(todos):\n",
    "    \"\"\"Check the same data that was modified above.\"\"\"\n",
    "    todo = todos[0]\n",
    "\n",
    "    assert not todo[\"completed\"]\n",
    "```\n",
    "\n",
    "Reference\n",
    "---------\n",
    "\n",
    "Glossary\n",
    "--------\n",
    "\n",
    "```{glossary} testing\n",
    "test suite\n",
    "  A collection of tests.\n",
    "\n",
    "test case\n",
    "  In testing a test case is the individual unit of testing that checks for a\n",
    "  specific response to a particular set of inputs.\n",
    "\n",
    "  In Pytest parametrization each combination of test and data (or parameters)\n",
    "  is a test case. Each set of parameters is stored in a list of tuples passed\n",
    "  as the second argument to `@pytest.mark.parametrize`.\n",
    "\n",
    "fixture\n",
    "fixtures\n",
    "  In a test suite the fixtures provide a defined, reliable and consistent\n",
    "  shared context for the tests. This includes any preperation that is required\n",
    "  for one or more tests to run and may include things like setup and teardown\n",
    "  such as creating a database or temporary directories; environment setup like\n",
    "  configuration; or data to be used in individual test cases.\n",
    "\n",
    "  In Pytest fixtures are defined as functions marked with the `@pytest.fixture`\n",
    "  decorator that may or may not return fixture data.\n",
    "\n",
    "  When programmers refer to \"a fixture\" it usually refers to a single record of\n",
    "  test data--for example, a single user record.\n",
    "\n",
    "fixture scope\n",
    "  In Pytest the scope of a fixture determines the lifespan of a fixture. That\n",
    "  is, at what level a fixture should be shared between tests before it is\n",
    "  destroyed, and thus a new instance created the next time it is requested.\n",
    "\n",
    "  The default is that a fixture should exist only for the scope of a single\n",
    "  test function. A fixture scope may also be for the class, module, package or\n",
    "  session.\n",
    "\n",
    "hello world\n",
    "Hello World\n",
    "Hello World!\n",
    "  A small piece of code used to demonstrate the most basic syntax and setup of\n",
    "  a particular language or tool. Most a program to print \"Hello World!\"\n",
    "```\n",
    "\n",
    "See also\n",
    "--------\n",
    "\n",
    "```{seealso}\n",
    "\n",
    "* [Effective Python Testing With Pytest](https://realpython.com/pytest-python-testing/)\n",
    "* [Testing Python Applications with Pytest](https://semaphoreci.com/community/tutorials/testing-python-applications-with-pytest)\n",
    "\n",
    "```\n",
    "\n",
    "----\n",
    "\n",
    "<!--\n",
    "\n",
    "TODO:\n",
    "-----\n",
    "\n",
    "- [x] filenames and test names\n",
    "- [x] skipping tests (`@pytest.mark.skip()`, `pytest.skip()`, `@pytest.mark.xfail()`)\n",
    "- [x] exceptions\n",
    "- [x] capsys\n",
    "- [x] params\n",
    "- [ ] fixtures\n",
    "    - [x] param fixtures\n",
    "    - [ ] fixture fixtures\n",
    "    - [ ] `--fixtures` flag\n",
    "    - [ ] fixture factories\n",
    "    - [ ] fixture and params\n",
    "    - [ ] builtin fixtures\n",
    "- [ ] conftest.py\n",
    "- [x] setup and teardown\n",
    "- [ ] mocks and stubs\n",
    "- [ ] temp files/directories\n",
    "- [ ] vscode\n",
    "- [ ] testing with debugger\n",
    "  - [ ] [pdb++](https://github.com/pdbpp/pdbpp)\n",
    "  - [ ] [pdbr](https://pypi.org/project/pdbr/)\n",
    "\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "source_map": [
   11
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}